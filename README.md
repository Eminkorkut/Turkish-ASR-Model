# ðŸŽ™ï¸ GeliÅŸmiÅŸ TÃ¼rkÃ§e ASR Projesi (Modern Conformer & BPE)

Bu proje, TÃ¼rkÃ§e konuÅŸma tanÄ±ma (Automatic Speech Recognition) iÃ§in uÃ§tan uca, modern ve yÃ¼ksek performanslÄ± bir Ã§Ã¶zÃ¼m sunar. Google'Ä±n **Conformer** mimarisini temel alÄ±r ve OpenAI Whisper gibi SOTA modellerde gÃ¶rÃ¼len geliÅŸmiÅŸ tekniklerle (GELU, Relative Attention, BPE) gÃ¼Ã§lendirilmiÅŸtir.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![License](https://img.shields.io/badge/License-Proprietary-red)

## ðŸŒŸ Ã–zellikler

- **Modern Mimari:** Conformer (Convolution-augmented Transformer) bloklarÄ±.
  - **Relative Positional Encoding:** Uzun seslerde daha iyi zaman algÄ±sÄ±.
  - **GELU Aktivasyonu:** Daha hÄ±zlÄ± ve kararlÄ± eÄŸitim (Whisper tarzÄ±).
  - **Relative Multi-Head Attention:** BaÄŸÄ±msÄ±z pozisyon kodlamasÄ±.
- **GeliÅŸmiÅŸ Tokenizasyon:**
  - **SentencePiece (BPE):** Karakter yerine alt-kelime (Subword) parÃ§alama. Bu sayede kelime daÄŸarcÄ±ÄŸÄ± (`vocab_size`) geniÅŸler ve model dilbilgisi kurallarÄ±nÄ± daha iyi Ã¶ÄŸrenir.
- **GÃ¼Ã§lÃ¼ Veri HattÄ±:**
  - **Otomatik BÃ¶lÃ¼mleme:** Tek bir klasÃ¶rÃ¼ Train/Valid/Test olarak otomatik bÃ¶ler.
  - **Raw Wav DesteÄŸi:** Ã–n iÅŸleme gerekmeden `.wav` ve `.txt` dosyalarÄ±yla Ã§alÄ±ÅŸÄ±r.
  - **Data Augmentation:** SpecAugment (Time & Freq Masking) ile gÃ¼rÃ¼ltÃ¼ye direnÃ§.
- **Profesyonel EÄŸitim DÃ¶ngÃ¼sÃ¼:**
  - **CanlÄ± Metrikler:** Loss deÄŸerinin yanÄ±nda **WER (Word Error Rate)** ve **CER (Character Error Rate)** takibi.
  - **Mixed Precision:** FP16 eÄŸitimi ile daha hÄ±zlÄ± ve az bellek kullanÄ±mÄ±.
  - **OneCycleLR:** GeliÅŸmiÅŸ learning rate planlamasÄ±.
- **GeliÅŸmiÅŸ Ã‡Ä±karÄ±m (Inference):**
  - **Beam Search Decoding:** Greedy aramaya gÃ¶re Ã§ok daha baÅŸarÄ±lÄ± sonuÃ§lar.
  - **N-gram Language Model:** Basit dil modeli entegrasyonu (Decoding aÅŸamasÄ±nda).

## ðŸ“‚ Dizin YapÄ±sÄ±

```
ASR_Project/
â”œâ”€â”€ data/                # Veri ve Tokenizasyon ModÃ¼lleri
â”‚   â”œâ”€â”€ dataset.py       # Wav okuma ve oto-split mantÄ±ÄŸÄ±
â”‚   â”œâ”€â”€ tokenizer.py     # SentencePiece wrapper
â”‚   â””â”€â”€ preprocessing.py # Mel-Spectrogram dÃ¶nÃ¼ÅŸÃ¼mleri
â”œâ”€â”€ model/               # Derin Ã–ÄŸrenme Mimarisi
â”‚   â”œâ”€â”€ conformer.py     # Conformer bloklarÄ± ve ana model
â”‚   â””â”€â”€ attention.py     # Relative Multi-Head Attention
â”œâ”€â”€ trainer/             # EÄŸitim Motoru
â”‚   â””â”€â”€ trainer.py       # EÄŸitim, Validasyon, Checkpoint, Metrikler
â”œâ”€â”€ utils/               # AraÃ§lar
â”‚   â”œâ”€â”€ config.py        # ArgÃ¼man yÃ¶netimi (argparse)
â”‚   â”œâ”€â”€ decoding.py      # Beam Search ve LM
â”‚   â”œâ”€â”€ logger.py        # Loglama
â”‚   â””â”€â”€ metrics.py       # WER/CER hesabÄ± (jiwer)
â”œâ”€â”€ main.py              # EÄŸitim BaÅŸlatÄ±cÄ±
â”œâ”€â”€ inference.py         # Test/Tahmin Scripti
â”œâ”€â”€ spm_train.py         # Tokenizer EÄŸitim Scripti
â””â”€â”€ README.md            # DokÃ¼mantasyon
```

## ðŸš€ Kurulum

Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:

```bash
pip install torch torchaudio numpy scipy sentencepiece jiwer
```

## ðŸ› ï¸ KullanÄ±m

### 1. Veri HazÄ±rlÄ±ÄŸÄ± ve Tokenizer EÄŸitimi (Zorunlu)

EÄŸitime baÅŸlamadan Ã¶nce, veri setinizdeki metinleri tarayarak bir BPE (Byte Pair Encoding) modeli eÄŸitmelisiniz. Bu adÄ±m `tokenizer_bpe.model` dosyasÄ±nÄ± oluÅŸturur.

```bash
# Veri yolunu kendi klasÃ¶rÃ¼nÃ¼ze gÃ¶re dÃ¼zenleyin
python spm_train.py --data_path "C:/Veri/Klasorum" --vocab_size 1000
```

*Not: `vocab_size` deÄŸeri veri bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne gÃ¶re 1000, 2000, 5000 seÃ§ilebilir.*

### 2. Model EÄŸitimi (Training)

EÄŸitimi baÅŸlatmak iÃ§in sadece veri klasÃ¶rÃ¼nÃ¼ gÃ¶stermeniz yeterlidir. Sistem otomatik olarak train/valid/test ayrÄ±mÄ± yapar.

```bash
python main.py --data_path "C:/Veri/Klasorum" --epochs 50 --batch_size 16 --vocab_size 1000
```

**Opsiyonel Parametreler:**

- `--val_split 0.2`: Verinin %20'sini validasyon iÃ§in ayÄ±rÄ±r.
- `--checkpoint_dir "./kayitlar"`: Modellerin kaydedileceÄŸi yer.
- `--n_blocks 8` `--d_model 256`: Modelin derinliÄŸini ve geniÅŸliÄŸini ayarlar.

### 3. Test ve Tahmin (Inference)

EÄŸitilmiÅŸ bir modeli kullanarak ses dosyalarÄ±nÄ± metne Ã§evirmek iÃ§in:

```bash
python inference.py --wav_path "ornek_ses.wav" --model_path "checkpoints/best_model.pt"
```

**Beam Search KullanÄ±mÄ±:**
Daha iyi sonuÃ§lar iÃ§in beam geniÅŸliÄŸini artÄ±rabilirsiniz:

```bash
python inference.py --wav_path "test.wav" --model_path "model.pt" --beam_width 10
```

## ðŸ“Š Performans Takibi (Metrikler)

EÄŸitim sÄ±rasÄ±nda konsolda her epoch sonunda ÅŸunlarÄ± gÃ¶receksiniz:

- **Loss:** Modelin matematiksel hatasÄ±.
- **WER (Word Error Rate):** Kelime bazlÄ± hata oranÄ± (DÃ¼ÅŸÃ¼k olmasÄ± iyidir).
- **CER (Character Error Rate):** Harf bazlÄ± hata oranÄ±.

Ã–rnek Ã‡Ä±ktÄ±:

```
Epoch 10 | Validation Loss: 0.4523 | WER: 0.1250 | CER: 0.0410
```

## ðŸ§  Model Mimarisi DetaylarÄ±

Proje, **Conformer** makalesindeki (Gulati et al., 2020) mimariyi takip eder:

1. **SpecAugment:** GiriÅŸ spektrogramÄ±nda rastgele maskeleme.
2. **Convolution Subsampling:** Zaman boyutunu 4 kat kÃ¼Ã§Ã¼ltÃ¼r (HÄ±z kazandÄ±rÄ±r).
3. **Relative Positional Encoding:** Sesin akÄ±ÅŸ yÃ¶nÃ¼nÃ¼ modele Ã¶ÄŸretir.
4. **Macaron Style FFN:** Blok baÅŸÄ±nda ve sonunda yarÄ±mÅŸar Feed-Forward katmanÄ±.
5. **Multi-Head Self Attention:** Global baÄŸlamÄ± yakalar.
6. **Convolution Module:** Lokal Ã¶zellikleri (fonem geÃ§iÅŸleri) yakalar.

## ðŸ“„ License

This project is licensed under a modified MIT-style **Proprietary License**.

> **Permission is hereby granted, free of charge, to handle the Software, subject to the following restrictions:**
>
> 1. **Commercial Use:** Prohibited without written permission.
> 2. **Modification:** Prohibited without written permission.
> 3. **Distribution:** Prohibited without written permission.

See the `LICENSE` file for the full legal text.

---
*Developed by Muhammed Emin Korkut - Deep Zeka A.Åž*
